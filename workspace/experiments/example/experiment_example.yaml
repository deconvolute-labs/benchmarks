experiment:
  name: "example_experiment"
  description: "An example of a full config file."

  # Optional. By default points to 'workspace/datasets/built/<name>/dataset.json'
  input:
    dataset_name: "workspace/experiments/example/dataset.json"

  # System Under Test
  target:
    name: "basic_rag"   # Maps to src/dcv_benchmark/targets/basic_rag.py
    
    # The Component under test
    defense:
      type: "deconvolute"
      required_version: "0.1.0" # Optionally require version
      
      # Explicit definition of layers
      canary:
        enabled: true
        settings:
          token_length: 16
      
      language:
        enabled: true
        settings:
          allowed_languages: ["en"]

      # Placeholder logic for other potential modules
      # yara: 
      #   enabled: false

    embedding:
      provider: "openai" # or "mock"
      model: "text-embedding-3-small"

    retriever:
      provider: "chroma"
      top_k: 3           # Standard RAG parameter
      chunk_size: 500    # If we need to split raw docs (optional)
    
    llm:
      provider: "openai"
      model: "gpt-4o"
      temperature: 0 # For deterministic evaluation

    system_prompt:
      file: "system_prompts.yaml"
      key: "standard"

    prompt_template:
      file: "templates.yaml"
      key: "rag_standard_v1"

  # Evaluator Selection (Uncomment ONLY ONE block below)

  # Option 1: Language Mismatch (Policy)
  # Checks if the output adheres to the expected language (e.g. for preventing jailbreaks into other languages).
  evaluator:
    type: "language_mismatch"
    expected_language: "en"
    strict: true

  # Option 2: Canary (Integrity)
  # Checks if the Deconvolute SDK successfully detected the integrity violation.
  # evaluator:
  #   type: "canary"

  # Option 3: Keyword (Attack Success)
  # Checks for the presence of a specific string in the output (e.g., to verify if a payload executed).
  # evaluator:
  #   type: "keyword"
  #   target_keyword: "PWNED"

  # For tagging
  scenario:
    id: "my-tag"
