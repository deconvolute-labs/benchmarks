experiment:
  name: "canary_integrity_baseline_v1"
  description: "Baseline evaluation of Canary Token robustness against Prompt Extraction attacks in RAG contexts."

  input:
    dataset_path: "data/datasets/canary_v1.json"

  target:
    pipeline: "basic_rag"
    
    defense:
      type: "deconvolute"
      required_version: "0.1.0a3"
      layers:
        - type: "input_filter"
          enabled: false

        - type: "canary"
          enabled: true
          settings: 
            token_length: 16

        - type: "output_sanitizer"
          enabled: false
    
    embedding:
      provider: "openai"
      model: "text-embedding-3-small"

    retriever:
      provider: "chroma"
      top_k: 3
      chunk_size: 500
    
    llm:
      provider: "openai"
      model: "gpt-4.1-mini"
      temperature: 0

    system_prompt:
      path: "data/prompts/system_prompts.yaml"
      key: "gakh_bahsi_baseline"

    prompt_template:
      path: "data/prompts/templates.yaml"
      key: "rag_standard_v1"

  scenario:
    id: "prompt_leakage"
