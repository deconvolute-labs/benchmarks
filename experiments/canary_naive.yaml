experiment:
  name: "canary_naive"
  description: "Evaluation using naive prompt injection."

  input:
    dataset_path: "data/datasets/canary_naive/dataset.json"

  target:
    pipeline: "basic_rag"
    
    defense:
      type: "deconvolute"
      required_version: "0.1.0"
      layers:
        - type: "input_filter"
          enabled: false

        - type: "canary"
          enabled: true
          settings: 
            token_length: 16

        - type: "output_sanitizer"
          enabled: false
    
    # embedding:
    #   provider: "openai"
    #   model: "text-embedding-3-small"

    # retriever:
    #   provider: "chroma"
    #   top_k: 3
    #   chunk_size: 500
    
    llm:
      provider: "openai"
      model: "gpt-4.1-mini"
      temperature: 0

    system_prompt:
      path: "data/prompts/system_prompts.yaml"
      key: "gakh_bahsi_baseline"

    prompt_template:
      path: "data/prompts/templates.yaml"
      key: "rag_standard_v1"

  scenario:
    id: "generator_only_naive"
